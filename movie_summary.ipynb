{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOiuXGQzRKIrdVdmug3Uz5e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nyanta012/demo/blob/main/movie_summary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "・GPUを使用するのでランタイムのタイプの変更からGPUに設定する必要がある\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "E8jHRKBUJfvE",
        "outputId": "f193587e-0ad1-4896-9510-22720d6ee747"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n・GPUを使用するのでランタイムのタイプの変更からGPUに設定する必要がある\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpjCt-4iIblR",
        "outputId": "988c5ec1-e5b5-41cc-c0a5-288d5a569368"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting faster-whisper@ https://github.com/nyanta012/faster-whisper/archive/refs/heads/master.tar.gz\n",
            "  Downloading https://github.com/nyanta012/faster-whisper/archive/refs/heads/master.tar.gz\n",
            "\u001b[2K     \u001b[32m-\u001b[0m \u001b[32m13.5 kB\u001b[0m \u001b[31m48.7 kB/s\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting av==10.*\n",
            "  Downloading av-10.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.2/31.2 MB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ctranslate2<4,>=3.9\n",
            "  Downloading ctranslate2-3.12.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.7/31.7 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers==0.13.*\n",
            "  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m107.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from ctranslate2<4,>=3.9->faster-whisper@ https://github.com/nyanta012/faster-whisper/archive/refs/heads/master.tar.gz) (1.22.4)\n",
            "Requirement already satisfied: pyyaml<7,>=5.3 in /usr/local/lib/python3.9/dist-packages (from ctranslate2<4,>=3.9->faster-whisper@ https://github.com/nyanta012/faster-whisper/archive/refs/heads/master.tar.gz) (6.0)\n",
            "Building wheels for collected packages: faster-whisper\n",
            "  Building wheel for faster-whisper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for faster-whisper: filename=faster_whisper-0.1.0-py3-none-any.whl size=13988 sha256=5020b5b46b683bbac519fefb8741532ac5b54abc9cc4897f4bd795cb70bf1884\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ws4bc_4b/wheels/e7/6c/49/8cf262ab990e0f9835ae16806f9138d17376028f08132ec7b9\n",
            "Successfully built faster-whisper\n",
            "Installing collected packages: tokenizers, av, ctranslate2, faster-whisper\n",
            "Successfully installed av-10.0.0 ctranslate2-3.12.0 faster-whisper-0.1.0 tokenizers-0.13.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers==4.27.2\n",
            "  Downloading transformers-4.27.2-py3-none-any.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers==4.27.2) (1.22.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers==4.27.2) (4.65.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers==4.27.2) (3.11.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers==4.27.2) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers==4.27.2) (0.13.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers==4.27.2) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers==4.27.2) (23.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers==4.27.2) (2022.10.31)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.27.2) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.27.2) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.27.2) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.27.2) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.27.2) (2022.12.7)\n",
            "Installing collected packages: huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.13.4 transformers-4.27.2\n"
          ]
        }
      ],
      "source": [
        "!pip install \"faster-whisper @ https://github.com/nyanta012/faster-whisper/archive/refs/heads/master.tar.gz\"\n",
        "!pip install transformers==4.27.2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# whisper large-v2をhugging faceから取得して、ctranslate2でC++に変換&パラメータなどの量子化する\n",
        "from faster_whisper import WhisperModel\n",
        "\n",
        "!ct2-transformers-converter --model openai/whisper-large-v2 --output_dir whisper-large-v2-ct2 \\\n",
        "    --copy_files tokenizer.json --quantization float16\n",
        "\n",
        "model_path = \"whisper-large-v2-ct2/\"\n",
        "\n",
        "# Run on GPU with FP16\n",
        "model = WhisperModel(model_path, device=\"cuda\", compute_type=\"float16\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkUkPJU_Ifag",
        "outputId": "125a149e-8dda-4181-c182-1221d521d036"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading (…)lve/main/config.json: 100% 1.99k/1.99k [00:00<00:00, 322kB/s]\n",
            "Downloading pytorch_model.bin: 100% 6.17G/6.17G [00:34<00:00, 179MB/s]\n",
            "Downloading (…)neration_config.json: 100% 3.51k/3.51k [00:00<00:00, 547kB/s]\n",
            "Downloading (…)okenizer_config.json: 100% 800/800 [00:00<00:00, 280kB/s]\n",
            "Downloading (…)olve/main/vocab.json: 100% 836k/836k [00:00<00:00, 992kB/s]\n",
            "Downloading (…)/main/tokenizer.json: 100% 2.20M/2.20M [00:01<00:00, 2.07MB/s]\n",
            "Downloading (…)olve/main/merges.txt: 100% 494k/494k [00:00<00:00, 2.29MB/s]\n",
            "Downloading (…)main/normalizer.json: 100% 52.7k/52.7k [00:00<00:00, 248kB/s]\n",
            "Downloading (…)in/added_tokens.json: 100% 2.08k/2.08k [00:00<00:00, 668kB/s]\n",
            "Downloading (…)cial_tokens_map.json: 100% 2.08k/2.08k [00:00<00:00, 756kB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#text file を作成するための関数\n",
        "def create_txt_file(file_name=\"transcribe\", results=None, fast_whisper=True):\n",
        "    with open(f\"{file_name}.txt\", mode=\"w\") as f:\n",
        "        for index, _dict in enumerate(results):\n",
        "            if fast_whisper:\n",
        "              start_time = _dict[0] # start\n",
        "              end_time = _dict[1] # end\n",
        "              text = _dict[2] # text\n",
        "            else:\n",
        "              start_time = _dict[\"start\"]\n",
        "              end_time = _dict[\"end\"]\n",
        "              text = _dict[\"text\"]\n",
        "            s_h, e_h = int(start_time//(60 * 60)), int(end_time//(60 * 60))\n",
        "            s_m, e_m = int((start_time % (60 * 60))//60), int((end_time % (60 * 60))//60)\n",
        "            s_s, e_s = int(start_time % 60), int(end_time % 60)\n",
        "            f.write(f'{text}\\n')"
      ],
      "metadata": {
        "id": "JW6zP6p8Ij-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "srD3uBbZIkaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# google driveをマウントする\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dmXpyiZIkha",
        "outputId": "41c7298f-fb83-437d-d027-09913f80ece7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(\"/content/drive/MyDrive/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ryJlMC3UIvPN",
        "outputId": "a2ccd984-a301-458b-d520-5e018f7bc874"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Colab Notebooks', 'youtube', 'ReazonSpeech.mp4', 'old']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 文字起こしを行い、textファイルを作成する\n",
        "%%time\n",
        "file_name = \"/content/drive/MyDrive/ReazonSpeech.mp4\"\n",
        "results, _ = model.transcribe(file_name,\n",
        "                              language=\"ja\")\n",
        "\n",
        "create_txt_file(file_name=\"transcribe_faster_whisper\", results=results, fast_whisper=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Kogu98tI0pI",
        "outputId": "56b6b80e-2a3a-4af9-b76d-b5386bc5598e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1min 23s, sys: 4.07 s, total: 1min 27s\n",
            "Wall time: 1min 22s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cH1BDnWpI0wa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install langchain==0.0.125 openai==0.27.2 tiktoken==0.3.3\n",
        "\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter"
      ],
      "metadata": {
        "id": "PBjuGXpfI3XC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = \"***\""
      ],
      "metadata": {
        "id": "ujadAk3KI3ei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 文章の校正を行う\n",
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0, max_tokens=1000)\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 1000,\n",
        "    chunk_overlap  = 20,\n",
        "    length_function = len,\n",
        ")\n",
        "\n",
        "# 文字起こしした内容を分割する\n",
        "with open(\"transcribe_faster_whisper.txt\") as f:\n",
        "    transcribe_sentence = f.read()\n",
        "texts = text_splitter.split_text(transcribe_sentence)\n",
        "docs = [Document(page_content=t) for t in texts]"
      ],
      "metadata": {
        "id": "fHxkvU_7I8eO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"\n",
        "次の文章は動画の文字起こしです。句読点などを適宜追加して文章を校正してください。\n",
        "また、無駄に長い文章は、意味が変わらない範囲で短く修正してください。\n",
        "文章：{text}\n",
        "校正された文章：\n",
        "\"\"\"\n",
        "\n",
        "PROMPT = PromptTemplate(\n",
        "    input_variables=[\"text\"],\n",
        "    template=template,\n",
        ")\n",
        "\n",
        "llm_chain = LLMChain(\n",
        "    prompt=PROMPT, \n",
        "    llm=llm\n",
        ")"
      ],
      "metadata": {
        "id": "OwYKcDyXI-z_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 文章を校正して、テキストファイルを作成する\n",
        "from tqdm import tqdm\n",
        "\n",
        "proofread_sentences = []\n",
        "for i in tqdm(range(len(texts))):\n",
        "    proofread_sentences.append(llm_chain.run(texts[i]))\n",
        "\n",
        "with open(\"proofread.txt\", mode=\"w\") as f:\n",
        "    for text in proofread_sentences :\n",
        "        print_text = text.replace(\"\\n\\n\",\"\\n\")\n",
        "        f.write(f'{print_text}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLPauR-sI-6j",
        "outputId": "aa3b5e2d-5b25-4bb1-979c-b2a17a788e95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4/4 [01:37<00:00, 24.33s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-gkpG9Y1JTUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# langchainを使って要約する場合\n",
        "\n",
        "# 校正された文章を分割する\n",
        "with open(\"proofread.txt\") as f:\n",
        "    transcribe_sentence = f.read()\n",
        "texts = text_splitter.split_text(transcribe_sentence)\n",
        "docs = [Document(page_content=t) for t in texts]"
      ],
      "metadata": {
        "id": "p3JpEM4IJTct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"\n",
        "次の文章を日本語で簡潔に要約してください。\n",
        "文章：{text}\n",
        "\"\"\"\n",
        "\n",
        "PROMPT = PromptTemplate(\n",
        "    input_variables=[\"text\"],\n",
        "    template=template,\n",
        ")"
      ],
      "metadata": {
        "id": "oiyVWgtrJWrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = load_summarize_chain(llm, chain_type=\"map_reduce\", map_prompt=PROMPT, combine_prompt=PROMPT, verbose=True)\n",
        "summary = chain.run(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I15jX_GIJX4T",
        "outputId": "f14bcacb-2b63-4f89-c999-155d3069a4a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new MapReduceDocumentsChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "次の文章を日本語で簡潔に要約してください。\n",
            "文章：はい、みなさんこんにちは。AIブチマニアタです。\n",
            "本日は、高精度の文字起こしができるレアゾンスピッチを紹介していこうと思います。\n",
            "AIで高精度の文字起こしができるモデルとしては、オープンAIのウィスパーが有名なんですけども、先日日本語に特化したレアゾンスピッチというものが公開されました。\n",
            "この動画では、レアゾンスピッチを簡単に紹介した後に、実際に文字起こしをやってみたいと思います。\n",
            "誰でも使えるように、Googleコラボのリンクを貼っていますので、無料で高精度の文字起こしを試してみたい人や、最新の音声認識AIについて興味がある人は、ぜひ見ていってもらえればと思います。\n",
            "それでは、早速やっていきましょう。\n",
            "最初に、レアゾンスピッチの紹介なんですけども、レアゾンスピッチ聞いたことある人はあまりいないんじゃないかなというふうに思います。\n",
            "レアゾンスピッチっていうのは、株式会社レアゾンで開発された音声認識に関するモデルやデータのことを指しています。\n",
            "日本語の音声データや最新のブログなども公開されているので、興味がある人は概要欄にリンクを貼っていくので、見ていってもらえればと思います。\n",
            "今回紹介するレアゾンスピッチの音声認識モデルは、1セグ放送の録画データから取得した19,000時間のデータを学習させているということで、日本語に特化した音声認識モデルというふうに言えるかと思います。\n",
            "さらに、今現在も開発中で、年間1万時間以上学習データが増えているということなので、今後さらに日本語に対する文字起こしの精度向上が期待できそうです。\n",
            "また、ありがたいことに、モデルは商用利用可能で無償で公開されています。\n",
            "次に、精度の話になります。\n",
            "こちらは、各データセットに対する誤判定を表す指標になっていて、小さいほど精度が高いことを意味しています。\n",
            "これまで世界最高精度を持っているのは、ウィスパーのLarge V2というモデルで、グラフの中では、この網網の棒グラフのところですね。\n",
            "今回紹介するレアゾーンスピーチのNextというものは、この青い棒グラフになってまして、ウィスパーのLarge V2よりも精度が高いということが分かるかと思います。\n",
            "さらに、レアゾーンスピーチの特徴としては、パラメーターの数が小さくなっている点が挙げられます。\n",
            "\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "次の文章を日本語で簡潔に要約してください。\n",
            "文章：こちらのグラフは、横軸がパラメーターの大きさを表しており、縦軸が誤判定率を表しています。縦軸が誤判定率を表しています。ウィスパーLargeを見てみると、パラメーターが非常に大きくて誤判定率が低いという位置づけで、レアゾーンスピーチに関してはウィスパーのベースぐらいのパラメーターの数で誤判定がかなり低いことが分かります。なので、レアゾーンスピーチは比較的大規模な計算機がなくても動作させることができると思います。それでは実際に文字起こしを行う実装について解説していきたいと思います。それでは早速実装の方やっていきたいと思います。こちらのGoogleコラボのリンクは概要欄に貼っていますので、実際に文字起こしやってみたい人はそちらのリンクを参照していただければと思います。\n",
            "最初に、まず今回レアゾーンスピーチを使っていくんですけども、GPUという機械を使用すると高速に文字起こしをすることができます。Googleコラボの中でGPUを使用するには、こちら左上のランタイムのところを押してもらってランタイムのタイプを変更を押してもらえればと思います。そうすると、これハードウェアアクセラレーターというところで、私はすでにGPUというふうに設定しているんですけども、ノーンというふうになっている人はGPUというふうに設定して保存をしてもらえればと思います。私はすでにGPUに設定しているので特に何も起きないんですけども、ノーンからGPUに変更した場合は少し時間がかかるかなというふうに思います。\n",
            "こちらのGoogleコラボなんですけども、このセルと言われる単位でプログラムを実行していくというものになっています。実行の仕方は、このセルをクリックして選んでもらって、シフトとエンターを同時に押してもらえればと思います。\n",
            "最初に、まずレアゾーンスピーチをインストールします。これはちょっと時間がかかるかなというふうに思うので飛ばしたいと思います。今、インストールの方が完了しました。インストールが完了すると、こちら1というところで番号が振られるかなと思います。次のセルを選んで実行していきます。シフトとエンターですね。こちらで、このGoogleコラボの中で使うパッケージを選択しています。実行が終わると、これがクルクルが止まります。今、実行が終わりました。\n",
            "\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "次の文章を日本語で簡潔に要約してください。\n",
            "文章：続いて、モデルのインストールということでレアゾーンスピーチのモデルをインストールします。こちらも、このセルを選んで実行してもらえると思います。シフトとエンターですね。そうすると、いろいろとダウンロードされているかなというふうに思います。モデルのダウンロードが終了しましたので、続いて文字起こししたい動画をアップロードします。\n",
            "このセルを選んで、シフトエンターを押してもらうと、こういった形でファイル選択というところが出てくるので、こちらクリックしてもらえれば、自分のパソコンにあるファイルを選択できるようになります。今、選択しました。選択すると、アップロードされていて、100%というふうになって、終了しました。これ、今やっていることとしては、Google Colab上に動画のファイルをアップロードしているということになります。\n",
            "続いてですね、こちらのセルで、このリブロソーというラベルを使って前処理を行います。こちらも、このセルを選んで、シフトとエンターを押してもらえればと思います。今、実行が終わったので、最後にですね、このクリエイトファイルというところで、こちらを実行してもらえればと思うんですけども、こちら引数に、テキストかもしくはsrtファイルといって、字幕データの拡張子ですね、どちらも指定することができます。txtかsrtかというふうにして指定して実行してもらえればと思います。今、txtというふうに指定して実行してみます。そうすると、今、文字起こしが行われています。はい、だいたいですね、10秒ぐらいで文字起こしが終わりました。\n",
            "\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "次の文章を日本語で簡潔に要約してください。\n",
            "文章：で、文字起こしが終わったら、ここに番号が表示されていると思うんですけども、文字起こししたファイルですね、左側のこのファイルというところを押してもらうと、こういった画面が開くんですけども、ここにトランスクライブテキストというものができています。こちらをダブルクリックしてもらうと、この動画では、レアゾンスピーチの制度をテストするために撮っていますと、エアゾンスピーチになってますね。日本語の音声データを使用して学習を行われているモデルなので、日本語で文字起こしをしてみたりとっては、非常に良いモデルになると思います。というところで、文字起こしができるというのがわかるかと思います。はい、で、今、文字起こししてみたんですけども、ちょっと一部が長いかなというふうに思います。で、あとは、まあ、レアゾーンとかエアゾンというところが、ちょっと間違っているので、気になるんですけども。こちらは多分データとして、レアゾンというデータがなかったので、しょうがないのかなというふうに思います。で、こちらの長さの件に関しては、サンプルレートですね。この2万というところですね、調整してあげるとちゃんと区切りができて、うまく文字起こしされるんじゃないかというところで、1万3000ぐらいにしてみたいと思います。で、これで実行します。先ほどテキストデータだったので、今回ですね、srtファイルというふうにしたいと思います。で、それは、えっと、srtというふうに、ここ打ってあげてで、実行してもらえればと思います。はい、そうすると、今文字起こしが終わったんですけども、ちょっとファイル出てこないという時は、この更新ボタンを、押してもらえればと思います。はい、そうすると、これ出てきました。で、これをダブルクリックします。そうすると、こういった形で、先ほどよりはしっかりと区切りができているのかなというふうに思います。サンプリングレートの取り方は、おそらく話し方によって変わってくるかなというふうに思うので、うまく区切りができないなって人は、色々といじってみる必要があるのかなというふうに思います。また、長い動画に対してどんなのかとか、あとはウィスパーと比較して、どれぐらい予測精度いいのかなっていうのは、ちょっと私もまだ検証できてない部分があるので、視聴者の方でもし、実際にやってみて感じたこととかですね、ぜひコメントの方で教\n",
            "\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "次の文章を日本語で簡潔に要約してください。\n",
            "文章：じたこととかですね、ぜひコメントの方で教えていただけるとありがたいなと思います。以上で、レアゾンスピーチに関する紹介の動画を終わりたいと思います。この動画が良かったなというふうに思う人は、高評価、コメント、チャンネル登録の方よろしくお願いします。それでは、また次回の動画でお会いしましょう。バイバイ。\n",
            "\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:/usr/local/lib/python3.9/dist-packages/langchain/chat_models/openai.py:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-qA1MFtLr2IRlqqP9CV4ybUAC on requests per min. Limit: 3 / min. Please try again in 20s. Contact support@openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:/usr/local/lib/python3.9/dist-packages/langchain/chat_models/openai.py:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-qA1MFtLr2IRlqqP9CV4ybUAC on requests per min. Limit: 3 / min. Please try again in 20s. Contact support@openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:/usr/local/lib/python3.9/dist-packages/langchain/chat_models/openai.py:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-qA1MFtLr2IRlqqP9CV4ybUAC on requests per min. Limit: 3 / min. Please try again in 20s. Contact support@openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:/usr/local/lib/python3.9/dist-packages/langchain/chat_models/openai.py:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-qA1MFtLr2IRlqqP9CV4ybUAC on requests per min. Limit: 3 / min. Please try again in 20s. Contact support@openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:/usr/local/lib/python3.9/dist-packages/langchain/chat_models/openai.py:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-qA1MFtLr2IRlqqP9CV4ybUAC on requests per min. Limit: 3 / min. Please try again in 20s. Contact support@openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "次の文章を日本語で簡潔に要約してください。\n",
            "文章：本日は、日本語に特化した音声認識モデル「レアゾンスピッチ」を紹介し、Googleコラボのリンクを貼って無料で高精度の文字起こしを試せることを伝えました。レアゾンスピッチは、19,000時間の1セグ放送の録画データから学習され、精度はウィスパーのLarge V2よりも高いとされています。また、パラメーターの数が小さい点も特徴的です。商用利用可能で無償で公開されているため、今後の日本語に対する文字起こしの精度向上が期待されます。\n",
            "\n",
            "グラフには、パラメーターの大きさと誤判定率が表示されており、レアゾーンスピーチは比較的大規模な計算機がなくても動作することができる。Googleコラボを使用する場合、GPUを使用することで高速に文字起こしを行うことができる。Googleコラボのセルを実行することで、レアゾーンスピーチをインストールし、必要なパッケージを選択することができる。\n",
            "\n",
            "Google Colab上にレアゾーンスピーチのモデルをインストールし、文字起こししたい動画をアップロードして前処理を行い、クリエイトファイルでテキストかsrtファイルを指定して実行すると、文字起こしが終わる。\n",
            "\n",
            "文字起こしの方法を説明し、トランスクライブテキストを使用することで、日本語の音声データを学習するモデルが非常に良いと述べている。しかし、一部の長さや間違いがあるため、サンプルレートを調整する必要がある。また、長い動画に対してどのように機能するかや、ウィスパーと比較して予測精度がどの程度良いかについては、まだ検証されていない。\n",
            "\n",
            "コメント欄で意見を教えてほしいと思います。以上で、レアゾンスピーチに関する紹介の動画を終わります。良かったら高評価、コメント、チャンネル登録をお願いします。また次回の動画で会いましょう。\n",
            "\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:/usr/local/lib/python3.9/dist-packages/langchain/chat_models/openai.py:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-qA1MFtLr2IRlqqP9CV4ybUAC on requests per min. Limit: 3 / min. Please try again in 20s. Contact support@openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:/usr/local/lib/python3.9/dist-packages/langchain/chat_models/openai.py:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-qA1MFtLr2IRlqqP9CV4ybUAC on requests per min. Limit: 3 / min. Please try again in 20s. Contact support@openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:/usr/local/lib/python3.9/dist-packages/langchain/chat_models/openai.py:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-qA1MFtLr2IRlqqP9CV4ybUAC on requests per min. Limit: 3 / min. Please try again in 20s. Contact support@openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(summary.replace(\"。\", \"。\\n\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMPN8rHQJXBQ",
        "outputId": "9a9dee0e-6ea8-47eb-942f-958718d8e5c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "本日は、日本語に特化した音声認識モデル「レアゾンスピッチ」を紹介し、Googleコラボのリンクを貼って無料で高精度の文字起こしを試せることを伝えました。\n",
            "レアゾンスピッチは、19,000時間の1セグ放送の録画データから学習され、精度はウィスパーのLarge V2よりも高いとされています。\n",
            "商用利用可能で無償で公開されているため、今後の日本語に対する文字起こしの精度向上が期待されます。\n",
            "Googleコラボを使用することで、高速に文字起こしを行うことができます。\n",
            "ただし、長い動画に対してどのように機能するかや、予測精度がどの程度良いかについては、まだ検証されていません。\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PPrvm46FJZ3k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}